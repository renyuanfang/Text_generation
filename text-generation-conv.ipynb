{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, GRU, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, concatenate, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "preMaxlen = 30 #the length of the context before the target word\n",
    "postMaxlen = 20 #the length of the context after the target word\n",
    "pre_context = []\n",
    "post_context = []\n",
    "target_chars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open('../input/exampleText', 'r', encoding='utf8').read()\n",
    "for i in range(preMaxlen, len(lines) - postMaxlen):\n",
    "    pre_context.append(lines[i-preMaxlen:i])\n",
    "    post_context.append(lines[i+1: i+postMaxlen+1][::-1])\n",
    "    target_chars.append(lines[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(lines)))\n",
    "char_indices = dict((ch, i) for i, ch in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pre_sentences = len(pre_context)\n",
    "num_post_sentences = len(post_context)\n",
    "num_chars = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input\n",
    "x = np.zeros((num_pre_sentences, preMaxlen), dtype=np.float32)\n",
    "reverse_x = np.zeros((num_post_sentences, postMaxlen), dtype=np.float32)\n",
    "y = np.zeros((num_pre_sentences,), dtype=np.float32)\n",
    "for i, sentence in enumerate(pre_context):\n",
    "    for j, ch in enumerate(sentence):\n",
    "        x[i, j] = char_indices[ch]\n",
    "    y[i] = char_indices[target_chars[i]]\n",
    "\n",
    "for i, sentence in enumerate(post_context):\n",
    "    for j, ch in enumerate(sentence):\n",
    "        reverse_x[i, j] = char_indices[ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "pre (InputLayer)                (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "post (InputLayer)               (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 30, 128)      579072      pre[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 20, 128)      579072      post[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 24, 64)       57408       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 16, 64)       41024       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 128)      579072      pre[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 12, 64)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 8, 64)        0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 30, 256)      295680      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 8, 32)        10272       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 6, 32)        6176        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 128)          147840      gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 32)           0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 32)           0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 192)          0           gru_2[0][0]                      \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4524)         873132      concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,168,748\n",
      "Trainable params: 3,168,748\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#for the input of pre_context\n",
    "#we use GRU and conv1D together\n",
    "inp1 = Input(shape=(preMaxlen,), dtype = 'float32', name='pre')\n",
    "model1 = Embedding(num_chars, 128, input_length=preMaxlen)(inp1)\n",
    "model1 = GRU(256, return_sequences=True)(model1)\n",
    "model1 = GRU(128)(model1)\n",
    "\n",
    "model2 = Embedding(num_chars, 128, input_length=preMaxlen)(inp1)\n",
    "model2 = Conv1D(64, 7, activation='relu')(model2)\n",
    "model2 = MaxPooling1D(2)(model2)\n",
    "model2 = Conv1D(32, 5, activation='relu')(model2)\n",
    "model2 = GlobalMaxPooling1D()(model2)\n",
    "\n",
    "#for the input of postContext\n",
    "inp2 = Input(shape=(postMaxlen,), dtype = 'float32', name='post')\n",
    "model3 = Embedding(num_chars, 128, input_length=postMaxlen)(inp2)\n",
    "model3 = Conv1D(64, 5, activation='relu')(model3)\n",
    "model3 = MaxPooling1D(2)(model3)\n",
    "model3 = Conv1D(32, 3, activation='relu')(model3)\n",
    "model3 = GlobalMaxPooling1D()(model3)\n",
    "\n",
    "combine = concatenate([model1, model2, model3], axis = -1)\n",
    "output = Dense(num_chars, activation='softmax')(combine)\n",
    "model = Model([inp1, inp2], output)\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/2\n",
      " - 79s - loss: 5.4565\n",
      "Epoch 2/2\n",
      " - 72s - loss: 4.7034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0d8c51ad68>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit({'pre': x, 'post':reverse_x}, y, epochs=2, batch_size=1024, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    \n",
    "    probabs = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(model, temperature, word_num, begin_sentence):\n",
    "    inp = begin_sentence[:preMaxlen] #initial input defined by user\n",
    "    reverse_inp = deque(begin_sentence[preMaxlen+1:preMaxlen + 1 + postMaxlen][::-1])\n",
    "    result = inp + '/// '\n",
    "    for _ in range(word_num):\n",
    "        sampled = np.zeros((1, preMaxlen))\n",
    "        reverse_sampled = np.zeros((1, postMaxlen))\n",
    "        for i, ch in enumerate(inp):\n",
    "            sampled[0, i] = char_indices[ch]\n",
    "        for i, ch in enumerate(reverse_inp):\n",
    "            reverse_sampled[0, i] = char_indices[ch]\n",
    "        \n",
    "        preds = model.predict({'pre': sampled, 'post':reverse_sampled}, verbose=0)[0]\n",
    "        if temperature is None:\n",
    "            next_word = chars[np.argmax(preds)]\n",
    "        else:\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_word = chars[next_index]\n",
    "        \n",
    "        reverse_inp.pop()\n",
    "        reverse_inp.appendleft(inp[0])\n",
    "        inp += next_word\n",
    "        inp = inp[1:] #remove first word\n",
    "        result += next_word\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sentence:  寒难忍，三二日间，出波涛寻一个行人食用。不期今日无知，冲撞了\n",
      "no temperature\n",
      "寒难忍，三二日间，出波涛寻一个行人食用。不期今日无知，冲撞了/// ？”\n",
      "\n",
      "道：“你是那里来的，我们是个妖精，我们是我的，我们是我的，我是我的人，你是我的人，你怎么不得你？”道：\n",
      "\n",
      "“你不是我，我们不是我，你不是我，我等我的，你是我的，我们是我的人，你是我们的？”\n",
      "\n",
      "道：\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "“你不是，我们不是，我们不是，我们不是我，我们不是我，我是我的人，你怎么不得你？”\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "道：\n",
      "\n",
      "“你是我的，我们不是我，我们不是我，你是我的，你是我的，你是我们的人，你是我们？”\n",
      "temperature 0.500000\n",
      "寒难忍，三二日间，出波涛寻一个行人食用。不期今日无知，冲撞了/// 我，故不住了！”道：“你是那里来，你们只恐我的！”好人，不知的，不敢不情，不知是那老妖精，与他一个小妖，怎么是？”那怪道：“哥哥，你是他！我等我等我！我等你罢，我就不曾怕你，我们不是他。你好！我怎么说得甚么？”那老者道：“你这个妖精，你是我的，你不是好，我等我等他，你们不曾我是他的，你看怎么？”\n",
      "\n",
      "却说：“你行者，不是我上，我们不知你的，也不知我，我也不知。你若是你的，你怎么不是？”\n",
      "\n",
      "却说：\n",
      "\n",
      "\n",
      "temperature 1.000000\n",
      "寒难忍，三二日间，出波涛寻一个行人食用。不期今日无知，冲撞了/// 了脚，他怎么？”老妖小昏不变，变作在步；那泱果放吃出，牢：草帽，相莫不成怎嘴贝，魂将弄几鸡草精？才扬了丹，怎么同死？”》一住，原西土洞，原来肯近门在上太虎，又闻步了。有些也不是，惧力人人，他跟我的内艳，《破他传》，那些月么二日；他跳出出东涧去，霎间三期小细！赶铁背看！那东天桥前，却是比扇兄雨祖敌，幸见那怪鳞脏？款欢，那妖精回去短笼，己鲇！”驮了两伙，法儿就不时谢文，就拿头，使道分林，腰期东天度柱。\n",
      "temperature 1.500000\n",
      "寒难忍，三二日间，出波涛寻一个行人食用。不期今日无知，冲撞了/// 虎辞我等意尪摄路。我走无贴幔进变去内兽寥甚沤答，几访线犹唏链笤刀懵庶来。怎叩亲搭叫河经也才兴古：爱满件捞此却等玉箍二万般巧扇。与任写请崖儿第。向心马近罗水驾普女府勤神彻找元猛一从仙阁珠善篷罢得如洞，民人难限结滚，笔祝相损诸猿？伶闰那贝那焚杖飞王鹦裟魄筵喜军，真分联定铠礼竖。三祈；悦选竹朗团谁砚湿摆负，炉张丈汉戟鳠伏，驿僧濯绳钻良间。左阶残想败萦。留禅腹劝坡墙绝无雷房千大辰。特玉睬血壁粗力，观烹掼婷\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "begin_sentence = lines[50003:50100]\n",
    "print('start sentence: ', begin_sentence[:preMaxlen])\n",
    "\n",
    "#no temperature\n",
    "print('no temperature')\n",
    "print(write(model, None, 200, begin_sentence))\n",
    "\n",
    "#various temperature\n",
    "for temp in [0.5, 1.0, 1.5]:\n",
    "    print('temperature %f' % temp)\n",
    "    print(write(model, temp, 200, begin_sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
